{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "1_Intro_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6ljihIGyQDj"
      },
      "source": [
        "## Una introducción práctica a Pytorch, https://pytorch.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07BVJ8DEyQDl"
      },
      "source": [
        "El objetivo de esta primera lección es el de arrojar un vistazo preliminar a las capacidades de la librería pytorch. Pytorch es un framework de deep learning con un estilo muy familiar al de numpy (https://numpy.org/).\n",
        "\n",
        "Como recordatorio, los objetos principales de numpy (y en cualquier librería de cálculo científico) son los arrays, y las operaciones que podemos calcular sobre ellos, por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GysXP1xJyQDm"
      },
      "source": [
        "# Para instalar las últimas versiones\n",
        "# !conda install -c pytorch torchvision -y\n",
        "# o\n",
        "# !pip install torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_On7B03HyQDm"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[1., 2.], [3., 4.]])\n",
        "B = np.array([[0., 1.], [0., 1.]])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QZrBFzsyQDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97abc37c-09f5-4852-ba35-73e4b1a602f9"
      },
      "source": [
        "C = A + B\n",
        "C"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 3.],\n",
              "       [3., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOf4sQgyyQDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "decd19d3-36c5-4484-93e9-a65243a64472"
      },
      "source": [
        "np.sum(A)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQs4G7PnyQDn"
      },
      "source": [
        "Pytorch es similar, solo que los objetos principales reciben el nombre de tensores (arrays multidimensionales)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teV9cBM7yQDn"
      },
      "source": [
        "import torch\n",
        "\n",
        "A = torch.tensor([[1., 2.], [3., 4.]])\n",
        "B = torch.tensor([[0., 1.], [0., 1.]])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZCpRMDT6SHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae9a87b-505c-4107-d10e-23c68a1306af"
      },
      "source": [
        "A"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxY7kK96yQDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8211fd61-f8a6-4b66-8079-65c284996355"
      },
      "source": [
        "C = A + B\n",
        "C"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 3.],\n",
              "        [3., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeH9zLbhyQDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b868244-ded8-4668-b053-a9065362ab27"
      },
      "source": [
        "torch.sum(A)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls4zyXtYyQDo"
      },
      "source": [
        "¡Así de simple es! Casi cualquier función de numpy (y de scipy) tiene un equivalente en pytorch. La lista completa de funciones puede consultarse en https://pytorch.org/docs/stable/torch.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K39hyZpqyQDo"
      },
      "source": [
        "Podemos convertir entre arrays de numpy y tensores de torch usando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEEJIhgpyQDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e68796-02b1-4ac5-c6bb-4f86b02ed857"
      },
      "source": [
        "C.numpy()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 3.],\n",
              "       [3., 5.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcTxB4iLyQDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59e77303-1692-4a75-d5ce-d897e41f70c2"
      },
      "source": [
        "torch.from_numpy(C.numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 3.],\n",
              "        [3., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEGYBO-vyQDp"
      },
      "source": [
        "Un atributo de los tensores muy útil (especialmente para depurar código) es .shape, que nos devuelve las dimensiones de nuestro tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn4wu9rgrqTi",
        "outputId": "f4b635b3-13c9-4427-b74e-ce1fa262ce03"
      },
      "source": [
        "C"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 3.],\n",
              "        [3., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS_X1GZCyQDp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e2ffb2-1843-48d5-8722-90b10b9af89f"
      },
      "source": [
        "C.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N67TWEahrxIV",
        "outputId": "f12ff7c3-0015-4848-e84c-642ac88d5582"
      },
      "source": [
        "torch.ones(7).shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBQtT4AB7K6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46937d21-bebf-4145-f93c-948d6f9e5ce8"
      },
      "source": [
        "vector = torch.arange(10)\n",
        "vector"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BReZSkcv7ViI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a2d68a1-20bf-4b0c-aede-8dac5ccf3e5d"
      },
      "source": [
        "vector[-3:]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Afu9BJRxyQDp"
      },
      "source": [
        "### Entonces, ¿por qué usar pytorch en vez de numpy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI5dqQYxyQDp"
      },
      "source": [
        "Hasta ahora, parece que pytorch hace lo mismo que numpy. Pero tiene un montón de extensiones que lo hacen especialmente útil para aplicaciones de ML/AI. Veamos las más importantes\n",
        "\n",
        "1. **Autograd** (diferenciación automática)\n",
        "\n",
        "2. **GPU**\n",
        "\n",
        "3. **Abstracciones** para ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_dThEOpyQDq"
      },
      "source": [
        "#### Diferenciación automática"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2jnrQ2vyQDq"
      },
      "source": [
        "Pytorch puede calcular el gradiente de cualquier función que podáis escribir utilizando tensores. No necesitamos calcular las derivadas (gradientes) a mano. Pytorch tampoco las calcula mediante diferencias numéricas (daría lugar a resultados aproximados o peor aún, inestables). En su lugar, pytorch va llevando un registro de todas las operaciones que definimos, y luego aplica la regla de la cadena estratégicamente (de forma simbólica), con lo que el resultado es una derivada exacta: https://en.wikipedia.org/wiki/Automatic_differentiation\n",
        "\n",
        "Para hacer esto, solo tenemos que activar un flag en las variables sobre las cuales queramos derivar/calcular gradiente. Por ejemplo, definamos una función $f(x) = \\sum_{i=1}^{10} x_i^2$, donde $x \\in \\mathbb{R}^{10}$, y supongamos que queramos calcular $\\nabla f(x)$ en $x = (1, 1, \\ldots, 1)$\n",
        "\n",
        "Primero, definimos el input. Esta vez, en vez de usar torch.tensor, usaremos torch.ones, similar a numpy.\n",
        "Pero fijémonos en que hemos añadido la opción de que estamos interesados en calcular gradientes respecto a esta variable en el futuro próximo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIICjF7kyQDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4117fe2-3aed-4f76-ae9e-dd04c48b5e91"
      },
      "source": [
        "x = torch.ones(10, requires_grad=True)\n",
        "x"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJIdFgFjyQDr"
      },
      "source": [
        "Ahora, definimos las operaciones de la función. Podríamos meter todo dentro de una función de python, pero esto no es necesario realmente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3xY7mvmyQDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecbf04c0-e5d6-4119-81e6-d4e1b59caecd"
      },
      "source": [
        "y = torch.sum(x**2)\n",
        "y"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSc0XYvOyQDr"
      },
      "source": [
        "Y finalmente, solo tenemos que invocar al método backward() para calcular la derivada $\\frac{\\partial y}{\\partial x}$. Entonces, podemos consular el atributo .grad de cualquier variables de input (para la que hayamos activado el flag requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7036kcEyQDs"
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3JE41SqyQDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e98290-4453-46b5-bd7d-986da1423f65"
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqfVfuXgyQDs"
      },
      "source": [
        "Esto era un ejemplo muy sencillo, pero lo cierto es que se pueden calcular derivadas a través de código muy complejo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoy_HHCHyQDs"
      },
      "source": [
        "x = torch.ones(5, requires_grad=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaV_VI6gyQDs"
      },
      "source": [
        "z = x\n",
        "while z[0] >= 0.2:\n",
        "    z = torch.sin(z)\n",
        "y = torch.sum(z)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d07e6cERyQDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414a5a6b-ddcb-4fc1-ca68-c0572e49bbff"
      },
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0062, 0.0062, 0.0062, 0.0062, 0.0062])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNMOEUo1yQDt"
      },
      "source": [
        "**Ejercicio** Dada $f(x_1,x_2) = sen(x_1)*cos(x_1*x_2)^2$, calcula $\\frac{\\partial f}{\\partial x_1}$ en $(x_1, x_2) = (2, 2)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLf1Q3ByQDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b4f7606-970f-4601-e9fc-2f077c9283ae"
      },
      "source": [
        "x = torch.tensor([2.0, 2.0], requires_grad=True)\n",
        "x"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--NmRD7MwIIs"
      },
      "source": [
        "y = torch.sin(x[0]) * torch.cos(x[0] * x[1]) ** 2"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mEesKnjwaan",
        "outputId": "2bc50ed1-bec9-4da7-a57f-f5ff472f9e3f"
      },
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.9770, -1.7992])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "gWMDldImyQDt"
      },
      "source": [
        "#### Aceleración por tarjeta gráfica (GPU)\n",
        "\n",
        "La CPU de vuestros ordenadores posiblemente tendrá entre 4 y 16 cores, así que la paralelización es algo limitada. Si tenéis alguna tarjeta gráfica de nvidia con los drivers de cuda instalados, podéis usarla para acelerar cálculos sobre arrays (pues la GPU tiene muchos más cores)\n",
        "\n",
        "Veamos un ejemplo sencillo de calcular el cuadrado de una matriz aleatoria grande, utilizando numpy y pytorch en CPU, y pytorch en GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3d2gtVWyQDu"
      },
      "source": [
        "A = np.random.randn(5000, 5000)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsLDoahVyQDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d86545-57c1-48bc-fae1-2412ecd20459"
      },
      "source": [
        "%%timeit\n",
        "B = A ** 2"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 49 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-NSWbGPyQDu"
      },
      "source": [
        "A = torch.from_numpy(A)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXL_mhL4yQDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc44a005-eac0-4448-f5eb-4b62d29b2319"
      },
      "source": [
        "%%timeit\n",
        "B = A ** 2"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 48.2 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwONmtpIyQDu"
      },
      "source": [
        "Con pytorch, podemos calcular sobre la GPU simplemente invocando .to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z881jtJnyQDu"
      },
      "source": [
        "A = A.to('cuda')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n3W1bsYyQDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d970e3fc-3623-40b3-dbce-74cb31e64c92"
      },
      "source": [
        "%%timeit\n",
        "B = A ** 2"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 4.55 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1000 loops, best of 5: 2.26 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkvb-MdAyQDv"
      },
      "source": [
        "Impresionante! Hemos conseguido reducir el tiempo de cálculo de 28 ms a 2.5 ms, 10 veces más rápido!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "relFavBryQDv"
      },
      "source": [
        "#### Abstracciones para deep learning\n",
        "\n",
        "Además de lo anterior, pytorch nos ofrece sublibrerías conteniendo funciones ya definidas para deep learning.\n",
        "Por ejemplo:\n",
        "\n",
        "1. torch.nn contiene varios tipos de capas para las redes neuronales (https://pytorch.org/docs/stable/nn.html)\n",
        "\n",
        "2. torch.optim contiene varios optimizadores implementados, como SGD, Adam, etc (https://pytorch.org/docs/stable/optim.html)\n",
        "\n",
        "Cubriremos todo esto en los próximos cuadernos!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyj5yW1dyQDv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}